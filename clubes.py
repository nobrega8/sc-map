import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
from urllib.parse import urljoin
import re
import sys

# Configura√ß√µes
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}
TIMEOUT = 15
DELAY = 3

# URLs base para competi√ß√µes portuguesas e principais europeias
COMPETICOES = [
    # Portugal - Competi√ß√µes principais
    "https://www.zerozero.pt/edition.php?id=193392",  # Liga Portuguesa
    "https://www.zerozero.pt/edition.php?id=193393",  # Segunda Liga
    "https://www.zerozero.pt/edition.php?id=193395",  # Liga 3
    "https://www.zerozero.pt/edition.php?id=193394",  # Ta√ßa de Portugal
    "https://www.zerozero.pt/edition.php?id=193396",  # Superta√ßa
    
    # Portugal - Competi√ß√µes distritais
    "https://www.zerozero.pt/edition.php?tp=31",      # AF Lisboa
    "https://www.zerozero.pt/edition.php?tp=32",      # AF Porto
    "https://www.zerozero.pt/edition.php?tp=35",      # AF Braga
    "https://www.zerozero.pt/edition.php?tp=33",      # AF Aveiro
    "https://www.zerozero.pt/edition.php?tp=34",      # AF Coimbra
    
    # Competi√ß√µes europeias principais
    "https://www.zerozero.pt/edition.php?id=193441",  # Champions League
    "https://www.zerozero.pt/edition.php?id=193442",  # Europa League
    "https://www.zerozero.pt/edition.php?id=193443",  # Conference League
    
    # Principais ligas europeias
    "https://www.zerozero.pt/edition.php?id=193381",  # La Liga (Espanha)
    "https://www.zerozero.pt/edition.php?id=193384",  # Serie A (It√°lia)
    "https://www.zerozero.pt/edition.php?id=193379",  # Bundesliga (Alemanha)
    "https://www.zerozero.pt/edition.php?id=193377",  # Ligue 1 (Fran√ßa)
    "https://www.zerozero.pt/edition.php?id=189547",  # Premier League (Inglaterra)
]

def fazer_requisicao(url, max_tentativas=3):
    """Faz uma requisi√ß√£o HTTP com tratamento de erros melhorado e retry autom√°tico"""
    for tentativa in range(max_tentativas):
        try:
            response = requests.get(url, headers=HEADERS, timeout=TIMEOUT)
            response.raise_for_status()
            return response
        except requests.exceptions.RequestException as e:
            if tentativa == max_tentativas - 1:
                print(f"‚úó Erro final ao aceder {url}: {str(e)}")
                return None
            else:
                print(f"‚ö† Tentativa {tentativa + 1} falhou para {url}, tentando novamente...")
                time.sleep(DELAY)
    return None

def extrair_id_clube(url):
    """Extrai o ID do clube da URL para garantir unicidade"""
    match = re.search(r'/(\d+)/?$', url)
    return match.group(1) if match else None

def limpar_nome_clube(nome):
    """Limpa e normaliza o nome do clube"""
    if not nome:
        return ""
    
    # Remove espa√ßos extras e caracteres especiais
    nome = re.sub(r'\s+', ' ', nome.strip())
    nome = re.sub(r'[^\w\s\-\(\)\.\'\"√£√°√†√¢√™√©√®√´√≠√¨√Æ√Ø√≥√≤√¥√µ√∫√π√ª√º√ß√±]', '', nome, flags=re.IGNORECASE)
    
    # Remove sufixos comuns desnecess√°rios
    sufixos_remover = [' FC', ' CF', ' SC', ' CD', ' UD', ' AD', ' SAD']
    for sufixo in sufixos_remover:
        if nome.upper().endswith(sufixo):
            nome = nome[:-len(sufixo)].strip()
    
    return nome

def extrair_clubes_competicao(url):
    """Extrai clubes de uma competi√ß√£o com m√∫ltiplas estrat√©gias otimizadas"""
    response = fazer_requisicao(url)
    if not response:
        return []

    soup = BeautifulSoup(response.text, "html.parser")
    clubes_encontrados = {}  # Usar dict para evitar duplicados

    # Estrat√©gias otimizadas em ordem de prioridade
    estrategias = [
        # Estrat√©gia 1: Links diretos de equipas (mais confi√°vel)
        {
            'nome': 'Links diretos',
            'seletores': [
                'a[href*="/equipa/"]',
                'a[href*="/team/"]',
                'a[href*="/club/"]'
            ]
        },
        # Estrat√©gia 2: Tabelas de classifica√ß√£o e estat√≠sticas
        {
            'nome': 'Tabelas',
            'seletores': [
                'table tr td a[href*="/equipa/"]',
                'table.stats-table a[href*="/equipa/"]',
                'table.classification a[href*="/equipa/"]',
                '.table-responsive a[href*="/equipa/"]'
            ]
        },
        # Estrat√©gia 3: Listas e containers espec√≠ficos
        {
            'nome': 'Listas',
            'seletores': [
                'div.team-list a[href*="/equipa/"]',
                '.team-name[href*="/equipa/"]',
                '.club-list a[href*="/equipa/"]',
                'ul.teams a[href*="/equipa/"]'
            ]
        },
        # Estrat√©gia 4: Classes espec√≠ficas do ZeroZero
        {
            'nome': 'Classes espec√≠ficas',
            'seletores': [
                '.team-title[href*="/equipa/"]',
                '.club-name[href*="/equipa/"]',
                '.team-link[href*="/equipa/"]',
                'a.team[href*="/equipa/"]'
            ]
        }
    ]

    for estrategia in estrategias:
        for seletor in estrategia['seletores']:
            try:
                links = soup.select(seletor)
                if links:
                    print(f"    ‚Üí {estrategia['nome']}: {len(links)} links encontrados com '{seletor}'")
                    
                    for link in links:
                        href = link.get('href')
                        if not href or not ('/equipa/' in href or '/team/' in href or '/club/' in href):
                            continue
                        
                        # Extrair nome do clube
                        nome = link.text.strip()
                        if not nome:
                            # Tentar extrair de elementos filhos
                            texto_elementos = link.find_all(text=True, recursive=True)
                            nome = ' '.join([t.strip() for t in texto_elementos if t.strip()])
                        
                        nome = limpar_nome_clube(nome)
                        if not nome or len(nome) < 2:
                            continue
                        
                        # Construir URL completa
                        url_clube = urljoin("https://www.zerozero.pt", href)
                        clube_id = extrair_id_clube(url_clube)
                        
                        if clube_id and clube_id not in clubes_encontrados:
                            clubes_encontrados[clube_id] = (nome, url_clube)
                    
                    if clubes_encontrados:
                        break  # Se encontrou clubes com este seletor, n√£o tenta os outros
            
            except Exception as e:
                print(f"    ‚úó Erro com seletor '{seletor}': {e}")
                continue
        
        if clubes_encontrados:
            break  # Se encontrou clubes com esta estrat√©gia, n√£o tenta as outras

    clubes_lista = list(clubes_encontrados.values())
    if clubes_lista:
        print(f"    ‚úì Total de clubes √∫nicos extra√≠dos: {len(clubes_lista)}")
    
    return clubes_lista

def processar_todas_competicoes():
    """Processa todas as competi√ß√µes e retorna conjunto √∫nico de clubes"""
    todos_clubes = {}  # Usar dict com URL como chave para evitar duplicados
    total_competicoes = len(COMPETICOES)
    
    print(f"üîç Processando {total_competicoes} competi√ß√µes...")
    
    for i, url in enumerate(COMPETICOES, 1):
        print(f"\n[{i}/{total_competicoes}] {url}")
        
        try:
            novos_clubes = extrair_clubes_competicao(url)
            
            if novos_clubes:
                for nome, url_clube in novos_clubes:
                    if url_clube not in todos_clubes:
                        todos_clubes[url_clube] = (nome, url_clube)
                
                print(f"    ‚úì {len(novos_clubes)} clubes √∫nicos adicionados")
            else:
                print(f"    ‚ö† Nenhum clube encontrado")
                
        except Exception as e:
            print(f"    ‚úó Erro inesperado: {str(e)}")
        
        # Delay entre requisi√ß√µes para ser respeitoso
        if i < total_competicoes:
            time.sleep(DELAY)
    
    return list(todos_clubes.values())

def salvar_resultados(clubes, nome_arquivo="clubes_zerozero.csv"):
    """Salva os resultados em CSV com valida√ß√£o e relat√≥rio detalhado"""
    if not clubes:
        print("\n‚ö† Aviso: Nenhum clube foi encontrado para salvar.")
        return False
    
    try:
        # Criar DataFrame e processar dados
        df = pd.DataFrame(clubes, columns=["nome", "url"])
        
        # Remover duplicados por URL (mais confi√°vel que por nome)
        df_original_size = len(df)
        df = df.drop_duplicates(subset="url", keep='first')
        df_deduplicated_size = len(df)
        
        # Ordenar por nome para facilitar consulta
        df = df.sort_values("nome")
        
        # Salvar CSV
        df.to_csv(nome_arquivo, index=False, encoding="utf-8")
        
        # Relat√≥rio de resultados
        print(f"\n‚úì Sucesso! {df_deduplicated_size} clubes √∫nicos salvos em '{nome_arquivo}'")
        if df_original_size != df_deduplicated_size:
            print(f"  üìä {df_original_size - df_deduplicated_size} duplicados removidos")
        
        # Mostrar amostra dos resultados
        print(f"\nüìã Primeiros 10 clubes encontrados:")
        for i, (nome, url) in enumerate(df.head(10).values, 1):
            print(f"  {i:2d}. {nome}")
        
        if len(df) > 10:
            print(f"  ... e mais {len(df) - 10} clubes")
        
        return True
        
    except Exception as e:
        print(f"\n‚úó Erro ao salvar resultados: {str(e)}")
        return False

def criar_dados_teste():
    """Cria dados de teste quando n√£o √© poss√≠vel aceder √† internet"""
    clubes_teste = [
        ("Benfica", "https://www.zerozero.pt/equipa/benfica/22"),
        ("Porto", "https://www.zerozero.pt/equipa/porto/236"),
        ("Sporting", "https://www.zerozero.pt/equipa/sporting/23"),
        ("Braga", "https://www.zerozero.pt/equipa/braga/2460"),
        ("Vit√≥ria SC", "https://www.zerozero.pt/equipa/vitoria_guimaraes/2469"),
        ("Torreense", "https://www.zerozero.pt/equipa/torreense/2178"),
        ("Casa Pia", "https://www.zerozero.pt/equipa/casa_pia/2543"),
        ("Chaves", "https://www.zerozero.pt/equipa/chaves/2470"),
    ]
    return clubes_teste

def main():
    """Fun√ß√£o principal com modo de teste integrado"""
    print("üîç SC-Map - Extrator de Clubes ZeroZero")
    print("=" * 50)
    
    # Verificar argumentos da linha de comando
    modo_teste = "--test" in sys.argv
    
    try:
        if modo_teste:
            print("üß™ Modo de teste ativado - usando dados de exemplo")
            clubes = criar_dados_teste()
        else:
            clubes = processar_todas_competicoes()
        
        # Salvar resultados
        if salvar_resultados(clubes):
            print(f"\nüéâ Processo conclu√≠do com sucesso!")
            if modo_teste:
                print("üí° Para executar com dados reais, execute: python clubes.py")
        else:
            print(f"\n‚ùå Processo falhou ao salvar resultados.")
            
    except KeyboardInterrupt:
        print(f"\n‚èπ Processo interrompido pelo utilizador.")
    except Exception as e:
        print(f"\nüí• Erro inesperado: {str(e)}")
        print("üí° Tente executar em modo de teste: python clubes.py --test")

if __name__ == "__main__":
    main()